# kafka核心技术与实战

## Producer如何管理TCP连接

Apache Kafka的所有通信都是基于TCP的，而不是于HTTP或其他协议的

- 为什采用TCP?
  （1）TCP拥有一些高级功能，如多路复用请求和同时轮询多个连接的能力。
  （2）很多编程语言的HTTP库功能相对的比较简陋。
  名词解释：
  多路复用请求：multiplexing request，是将两个或多个数据合并到底层—个物理连接的过程。TCP的多路复用请求会在一条物理连接上创建若干个虚拟连接，每个虚拟连接负责流转各自对应的数据流。严格讲：TCP并不能多路复用，只是提供可靠的消息交付语义保证，如自动重传丢失的报文。

- 何时创建TCP连接？
  （1）在创建KafkaProducer实例时，

  A：生产者应用会在后台创建并启动一个名为Sender的线程，该Sender线程开始运行时，首先会创建与Broker的连接。
  B：此时不知道要连接哪个Broker，kafka会通过METADATA请求获取集群的元数据，连接所有的Broker。
  （2）还可能在更新元数据后，或在消息发送时

- 何时关闭TCP连接
（1）Producer端关闭TCP连接的方式有两种：用户主动关闭，或kafka自动关闭。
  A：用户主动关闭，通过调用producer.close()方关闭，也包括kill -9暴力关闭。
  B：Kafka自动关闭，这与Producer端参数connection.max.idles.ms的值有关，默认为9分钟，9分钟内没有任何请求流过，就会被自动关闭。这个参数可以调整。
  C：第二种方式中，TCP连接是在Broker端被关闭的，但这个连接请求是客户端发起的，对TCP而言这是被动的关闭，被动关闭会产生大量的CLOSE_WAIT连接。

## CommitFailedException
- 定义：所谓CommitFailedException，是指Consumer客户端在提交位移时出现了错误或异常，并且并不可恢复的严重异常。
- 导致原因：
  （1）消费者端处理的总时间超过预设的max.poll.interval.ms参数值
  （2）出现一个Standalone Consumerd的独立消费者，配置的group.id重名冲突。
- 解决方案：
  （1）减少单条消息处理的时间
  （2）增加Consumer端允许下游系统消费一批消息的最大时长
  （3）减少下游系统一次性消费的消息总数。
  （4）下游使用多线程加速消费



## Consumer如何管理TCP连接

- 何时创建
  A ：消费者和生产者不同，在创建KafkaConsumer实例时不会创建任何TCP连接。
  原因：是因为生产者入口类KafkaProducer在构建实例时，会在后台启动一个Sender线程，这个线程是负责Socket连接创建的。

- TCP连接是在调用KafkaConsumer.poll方法时被创建。在poll方法内部有3个时机创建TCP连接
  （1）发起FindCoordinator请求时创建
  Coordinator（协调者）消费者端组件，驻留在Broker端的内存中，负责消费者组的组成员管理和各个消费者的位移提交管理。
  当消费者程序首次启动调用poll方法时，它需要向Kafka集群发送一个名为FindCoordinator的请求，确认哪个Broker是管理它的协调者。

  （2）连接协调者时
  Broker处理了消费者发来的FindCoordinator请求后，返回响应显式地告诉消费者哪个Broker是真正的协调者。
  当消费者知晓真正的协调者后，会创建连向该Broker的socket连接。
  只有成功连入协调者，协调者才能开启正常的组协调操作。

  （3）消费数据时
  消费者会为每个要消费的分区创建与该分区领导者副本所在的Broker连接的TCP.

- 创建多少
  消费者程序会创建3类TCP连接：
  （1）：确定协调者和获取集群元数据
  （2）：连接协调者，令其执行组成员管理操作
  （3）：执行实际的消息获取

- 何时关闭TCP连接
  A ：和生产者相似，消费者关闭Socket也分为主动关闭和Kafka自动关闭。
  B ：主动关闭指通过KafkaConsumer.close()方法，或者执行kill命令，显示地调用消费者API的方法去关闭消费者。
  C ：自动关闭指消费者端参数connections.max.idle.ms控制的，默认为9分钟，即如果某个socket连接上连续9分钟都没有任何请求通过，那么消费者会强行杀死这个连接。
  D ：若消费者程序中使用了循环的方式来调用poll方法消费消息，以上的请求都会被定期地发送到Broker，所以这些socket连接上总是能保证有请求在发送，从而实现“长连接”的效果。
  E ：当第三类TCP连接成功创建后，消费者程序就会废弃第一类TCP连接，之后在定期请求元数据时，会改为使用第三类TCP连接。对于一个运行了一段时间的消费者程序来讲，只会有后面两种的TCP连接。

## kafka副本机制

- 副本机制的定义：所谓副本机制（Replication），也可以称之为备份机制，通常是指分布式在多台网络互连的机器上保存有相同的数据拷贝。
  副本机制的价值：A ：提供数据冗余 B ：提供高伸缩性 C ：改善数据局部性
  但 Kafka的副本机制，只实现了提供数据冗余的价值。

- 副本定义：
  A ：Kafka有主题的概念，每个主题又分为若干个分区。副本的概念是在分区层级下定义的，每个分区配置有若干个副本。
  B ：所谓副本（Replica），本质是一个只能追加写消息的提交日志。
  根据Kafka副本机制的定义，同一个分区下的所有副本保存有相同的消息序列，这些副本分散保存在不同的Broker上，从而能够对抗部分Broker宕机带来的数据不可用。

- 副本角色：
  A ：为解决分区下多个副本的内容一致性问题，常用方案就是采用基于领导者的副本机制。
  B ：在kafka中，副本分两类：领导者副本和追随者副本。每个分区在创建时都选举一个副本，称为领导者副本，其余的副本自动成为追随者副本。
  C ：Kafka的副本机制比其他分布式系统严格。Kafka的追随者副本不对外提供服务。所有的请求都要由领导者副本处理。追随者副本唯一的任务就是从领导者副本异步拉取消息，并写入到自己的提交日志中，从而实现与领导者副本的同步。
  D ：当领导者副本所在Broker宕机了，Kafka依托于Zookeeper提供的监控功能能够实时感知到，并立即开启新一轮的领导者选举，从追随者副本中选一个新的领导者。当老的Leader副本重启回来后，只能作为追随者副本加入到集群中。

- Kafka副本机制的优点：
  A ：方便实现“Read-your-writes”
  （1）含义：当使用生产者API向Kafka成功写入消息后，马上使用消息者API去读取刚才生产的消息。
  （2）如果允许追随者副本对外提供服务，由于副本同步是异步的，就可能因为数据同步时间差，从而使客户端看不到最新写入的消息。
  B ：方便实现单调读（Monotonic Reads）
  （1）单调读：对于一个消费者用户而言，在多处消息消息时，他不会看到某条消息一会存在，一会不存在。
  （2）如果允许追随者副本提供读服务，由于消息是异步的，则多个追随者副本的状态可能不一致。若客户端每次命中的副本不同，就可能出现一条消息一会看到，一会看不到。

- In-sync Replicas（ISR）同步副本
  A ：追随者副本定期的异步拉取领导者副本中的数据，这存在不能和Leader实时同步的风险。
  B ：Kafka引入了In-sync Replicas。ISR中的副本都是于Leader同步的副本，相反，不在ISR中的追随者副本就是被认为是与Leader不同步的。
  C ：Leader 副本天然就在ISR中，即ISR不只是追随者副本集合，他必然包括Leader副本。甚至某些情况下，ISR只有Leade这一个副本。
  D ：follower副本是否与leader同步的判断标准取决于Broker端参数 replica.lag.time.max.ms参数值。默认为10秒，只要一个Follower副本落后Leader副本的时间不连续超过10秒，那么Kafka就认为该Follower副本与leader是同步的，即使此时Follower副本中保存的消息明显小于Leader副本中的消息。
  E ：如果同步过程持续慢于Leader副本消息的写入速度，那么replica.lag.time.max.ms时间后，此Follower副本就会被认为是与Leader副本不同步的，因此不能再放入ISR中。此时，kafka会自动收缩ISR的进度，将该副本“踢出”ISR。ISR是一个动态调整的集合，而非静态不变的。

- Unclean 领导者选举（Unclean Leader Election）
  A ：ISR是可以动态调整的，所以会出现ISR为空的情况，由于Leader副本天然就在ISR中，如果ISR为空了，这说明Leader副本也挂掉了，Kafka需要重新选举一个新的Leader。
  B ：Kafka把所有不在ISR中的存活副本都会称为非同步副本。通常，非同步副本落后Leader太多，如果让这些副本做为新的Leader，就可能出现数据的丢失。在kafka中，选举这种副本的过程称为Unclean领导者选举。
  C ：Broker端参数unclean.leader.election.enable 控制是否允许Unclean领导者选举。开启Unclean领导者选举可能会造成数据丢失，但它使得分区Leader副本一直存在，不至于停止对外提供服务，因此提升了高可用性。禁止Unclean领导者选举的好处是在于维护了数据的一致性，避免了消息丢失，但牺牲了高可用性。

## kafka的HW、LEO、LSO

https://juejin.cn/post/6844903960768151566

## 请求如何被处理

https://www.processon.com/view/link/5d481e6be4b07c4cf3031755

- Apache Kafka 自己定义了组请求协议，用于实现各种交互操作。常见有：
  a. PRODUCE 请求用于生产消息
  b. FETCH请求是用于消费消息
  c. METADATA请求是用于请求Kafka集群元数据信息。

  Kafka定义了很多类似的请求格式，所有的请求都是通过TCP网络以Socket的方式进行通讯的。

- KaKfa Broker端处理请求的全流程
  A ：常用请求处理方案
  a：顺序处理请求
  实现方法简答，但吞吐量太差是致命缺陷。因为是顺序处理，每个请求都必须等待前一个请求处理完毕才能得到处理。这只适用于请求发送非常不频繁的系统。
  b：每个请求使用单独线程处理
  它是完全异步的，每个请求的处理都创建单独线程处理，但缺陷明显，为每个请求都创建线程开销极大，某些场景甚至会压垮整个服务。

  B ：Kafka的方案：使用Reactor模式
  a：Reactor模式是JUC包作者的作品
  b：Reactor模式是事件驱动架构的一种实现方式，特别适应用于处理多个客户端并发向服务端发送请求的场景。

- Kafka的请求处理方式
  A ：Reactor模式中，多个客户端发送请求到Reactor。Reactor有个请求分发线程Dispatcher，它会将不同的请求下发到多个工作线程中处理。
  Acceptor线程只用于请求分发，不涉及具体逻辑处理，因此有很高的吞吐量。而工作线程可以根据实际业务处理需要任意增减，从而动态调节系统负载能力。

  B ：kakfa中，Broker端有个SocketServer组件，类似于Reactor模式中的Dispatcher，他也有对应的Acceptor线程和一个工作线程池，在kafka中，被称为网络线程池。
  Broker端参数num.network.threads，用于调整该网络线程池的线程数，默认为4，表示每台Broker启动时，会创建3个网络线程，专门处理客户端发送的请求。

  C ：Acceptor线程采用轮询的方式将入站请求公平的发送到所有网络线程中。

  D ：当网络线程接收到请求后，Kafka在这个环节又做了一层异步线程池的处理。
  （1）当网络线程拿到请求后，她不是自己处理，而是将请求放入到一个共享请求队列中。
  （2）Broker端还有个IO线程池，负责从该队列中取出请求，执行真正的处理。如果是PRODUCE生产请求，则将消息写入到底层的磁盘日志中；如果是FETCH请求，则从磁盘或页缓存中读取消息。

  E ：IO线程池中的线程是执行请求逻辑的线程。Broker端参数num.io.threads控制了这个线程数，默认为8，表示每台Broker启动后自动创建8个IO线程处理请求。

  F ：请求队列是所有网络线程共享的，而响应队列则是每个网络线程专属的。原因在于Dispatcher只是用于请求分发而不负责响应回传，因此只能让每个网络线程自己发送Repsone给客户端，所有这些Response没必要放在一个公共的地方。

  G ：Purgatory组件，专门用来缓存延时请求（Delayed Requset）。如设置了acks=all的PRODUCE请求，该请求要必须等待ISR中所有副本都接收了消息后才能返回，此时处理该请求的IO线程就必须瞪大其他Broker的写入结果。当请求不能立即处理时，他就会暂存在Purgatory中。待满足了完成条件，IO线程会继续处理该请求，并将Response放入到对应的网络线程的响应队列中

- Kafka对请求的处理特点
  A ：Kafka Broker对所有的请求都是一视同仁的。
  B ：这些请求根据功能，可分为不同的请求类型。从业务的权重角度来讲，是有高低之分的，如控制类请求可以影响数据类请求。
  C ：无原则的平等，会造成混乱

  社区采取的方案是，同时创建两套完全样的组件，实现两类请求的分离。